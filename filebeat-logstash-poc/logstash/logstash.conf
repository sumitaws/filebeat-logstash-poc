input {
  beats {
    port => 5044
  }
}

filter {
  # Add an extra field for traceability
  mutate {
    add_field => { "ingested_at" => "%{@timestamp}" }
  }
}

output {
  # --- AWS S3 Output ---
  s3 {
    bucket => "my-log-bucket-elk"
    region => "us-east-1"

    # Organize logs by date in S3
    prefix => "logs/%{+YYYY}/%{+MM}/%{+dd}/"

    # Encode each event as a line
    codec => line

    # Rotate files to avoid too many small files
    size_file => 100       # Rotate after ~100 MB
    time_file => 300       # Or every 5 minutes
    restore => true
   
    # Prevent multiple small chunks:
    #size_file => 104857600   # 100 MB
    #rotation_strategy => "size"

    # Temp storage before upload
    temporary_directory => "/tmp/logstash-s3"
  }

  # --- Local Disk / EFS Output ---
  file {
    # Write logs per hour to keep files manageable
    path => "/usr/share/logstash/efs-data/logs-%{+YYYY-MM-dd_HH}.log"

    # Write only the message field
    codec => line { format => "%{message}" }

    # Flush every ~2MB to disk (default is buffered)
    flush_interval => 2
  }

  # --- Debug Output to Console ---
  stdout {
    codec => rubydebug { metadata => false }
  }
}
